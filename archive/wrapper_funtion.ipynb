{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 05:11:54.268501: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-14 05:11:54.504347: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-14 05:11:54.559277: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 05:11:57.258881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-14 05:11:57.263144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-14 05:11:57.263491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-14 05:11:57.263827: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-14 05:11:57.266203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-14 05:11:57.266634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-14 05:11:57.267230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-14 05:11:57.983169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-14 05:11:57.983817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-14 05:11:57.983840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-14 05:11:57.984202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-14 05:11:57.984289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5400 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# SSD with Mobilenet v2\n",
    "\n",
    "model_handle = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\n",
    "hub_model = hub.load(model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def get_cropped_images(image_path,hub_model):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if image is not None:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (320, 320))\n",
    "        image = image[np.newaxis, ...]\n",
    "        # image = tf.image.convert_image_dtype(image, tf.float32)[tf.newaxis, ...]\n",
    "        start_time = time.time()\n",
    "        result = hub_model(image)\n",
    "        end_time = time.time()\n",
    "        result = {key:value.numpy()[0] for key,value in result.items()}\n",
    "        \n",
    "        # filter results where detection_classes == 1\n",
    "        human_idx = np.where(result['detection_classes'] == 1)\n",
    "\n",
    "        human_results = {}\n",
    "        human_results['detection_boxes'] = result['detection_boxes'][human_idx]\n",
    "        human_results['detection_scores'] = result['detection_scores'][human_idx]\n",
    "        \n",
    "        cropped_results = []\n",
    "        output_image = image.copy()\n",
    "        for i in range(len(human_results['detection_boxes'])):\n",
    "            box = human_results['detection_boxes'][i]\n",
    "            box = [int(x * 320) for x in box]\n",
    "            conf_score = human_results['detection_scores'][i]\n",
    "            if conf_score > 0.5:\n",
    "                # write to output folder as image\n",
    "                cropped_img = image[0][box[0]:box[2], box[1]:box[3]]\n",
    "                if (cropped_img.shape[0] > 10) and (cropped_img.shape[1] > 10):\n",
    "                    cropped_img = cv2.cvtColor(cropped_img, cv2.COLOR_RGB2BGR)\n",
    "                    cropped_results.append(cropped_img.copy())\n",
    "                    \n",
    "                    # draw bounding box\n",
    "                    cv2.rectangle(output_image, (box[1], box[0]), (box[3], box[2]), (0, 255, 0), 2)\n",
    "                    \n",
    "        return cropped_results, output_image\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load classification modle \n",
    "\n",
    "clf_model = tf.keras.models.load_model('model/binary_22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_class(image, model,thresh = 0.22):\n",
    "    # Load the saved model\n",
    "\n",
    "    \n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    # scale the image\n",
    "    img_array = tf.image.resize(img_array, [32*2, 32])\n",
    "    \n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "    img_array /= 255.\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model(img_array)\n",
    "    predicted_thresh = predictions[0][0].numpy()\n",
    "    print(predicted_thresh)\n",
    "    if predicted_thresh < thresh:\n",
    "        return 'others'\n",
    "    else:\n",
    "        return 'zomato'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2167659\n",
      "0.2153042\n",
      "0.19858296\n",
      "0.2154769\n"
     ]
    }
   ],
   "source": [
    "classified_results = []\n",
    "\n",
    "cropped_results, output_image = get_cropped_images('data/test1.jpg',hub_model)\n",
    "\n",
    "if len(cropped_results)>= 1:\n",
    "\n",
    "    for image in cropped_results:\n",
    "        classified_results.append(predict_image_class(image,clf_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['others', 'others', 'others', 'others']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
